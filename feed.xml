<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://debjitpaul.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://debjitpaul.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-06-30T15:05:03+00:00</updated><id>https://debjitpaul.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">REFINER</title><link href="https://debjitpaul.github.io/blog/2023/custom-blockquotes/" rel="alternate" type="text/html" title="REFINER"/><published>2023-04-04T19:53:00+00:00</published><updated>2023-04-04T19:53:00+00:00</updated><id>https://debjitpaul.github.io/blog/2023/custom-blockquotes</id><content type="html" xml:base="https://debjitpaul.github.io/blog/2023/custom-blockquotes/"><![CDATA[<p>Language models (LMs) have recently shown remarkable performance on reasoning tasks by explicitly generating intermediate inferences, e.g., chain-of-thought prompting. However, these intermediate inference steps may be inappropriate deductions from the initial context and lead to incorrect final predictions. Here we introduce REFINER, a framework for finetuning LMs to explicitly generate intermediate reasoning steps while interacting with a critic model that provides automated feedback on the reasoning. Specifically, the critic provides structured feedback that the reasoning LM uses to iteratively improve its intermediate arguments. Empirical evaluations of REFINER on three diverse reasoning tasks show significant improvements over baseline LMs of comparable scale. Furthermore, when using GPT-3.5 as the reasoner, the trained critic significantly improves reasoning without finetuning the reasoner. Finally, our critic model is trained without expensive human-in-the-loop data but can be substituted with humans at inference time.</p>]]></content><author><name></name></author><category term="pre-print"/><category term="blockquotes"/><summary type="html"><![CDATA[Reasoning Feedback on Intermediate Representations]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://debjitpaul.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://debjitpaul.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://debjitpaul.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Social Commonsense Reasoning with Structured Knowledge in Text</title><link href="https://debjitpaul.github.io/blog/2022/phd-thesis/" rel="alternate" type="text/html" title="Social Commonsense Reasoning with Structured Knowledge in Text"/><published>2022-04-23T19:53:00+00:00</published><updated>2022-04-23T19:53:00+00:00</updated><id>https://debjitpaul.github.io/blog/2022/phd-thesis</id><content type="html" xml:base="https://debjitpaul.github.io/blog/2022/phd-thesis/"><![CDATA[<p>Understanding a social situation requires the ability to reason about the underlying emotions and behaviour of others. For example, when we read a \textit{personal story}, we use our prior commonsense knowledge and social intelligence to infer the emotions, motives, and anticipate the actions of the characters in a story. For machines to understand text related to \textit{personal stories and social conversations}, they must be able to make commonsense inferences. While most people can reason deeply about the social implications of the text, it is challenging for natural language processing systems as these implications are often subtle and implicit.</p> <p>This dissertation argues that NLP systems must learn to reason more explicitly about the underlying social knowledge in text to perform social commonsense reasoning. We divide the above argument into two sub-problems: (i) understanding the underlying social knowledge and (ii) explicitly reasoning about such knowledge for social commonsense reasoning. To address these problems, we propose building NLP systems that integrate neural network based learning with structured knowledge representations.</p> <p>In the first part of this dissertation, we study the role of structured commonsense knowledge in understanding the social dynamics of characters and their actions in stories. Our motivation behind enriching the model with structured commonsense knowledge is to bridge the gap between surface meanings of texts and the underlying social implication of each event in the stories. We develop a novel model that incorporates commonsense knowledge into neural models and showcases the importance of commonsense knowledge in understanding social dynamics of story characters. Further, we investigate the role of temporal dynamics of story events in understanding social situations. We develop a model that can explicitly learn about \textit{what social event follows another event} from personal narrative stories. We demonstrate that \textit{implicitly} leveraging such temporal knowledge about story events can support social commonsense reasoning tasks.</p> <p>In the second part of this dissertation, we investigate methods to explicitly reason about the knowledge related to social dynamics of characters (\textit{behavior, mental states}) and cause/effect of social events. We propose a novel model named as \textit{multi-head knowledge attention} that incorporates such social knowledge into state-of-the-art neural NLP models to address two complex commonsense inference tasks. We demonstrate that our method of incorporating knowledge can improve â€“ (i) the robustness and the interpretability of the model and (ii) the overall performance of the model compared to other knowledge integration methods. We also aim to investigate social commonsense reasoning as a natural language generation task. We design a story completion task that requires natural language generation models to perform both forward and backward reasoning. We study the role of contextualized commonsense knowledge in natural language generation tasks. We propose a model that jointly learns to generate contextualized inference rules as well as narrative stories. We demonstrate that our model can outperform state-of-the-art non-contextualized commonsense knowledge-based generation models.</p> <p>We hope that the research presented in this dissertation will open up interesting scopes for future research involving social commonsense reasoning and other related topics.</p>]]></content><author><name></name></author><category term="PhD_Thesis"/><category term="blockquotes"/><summary type="html"><![CDATA[Social Commonsense Reasoning with Structured Knowledge in Text]]></summary></entry></feed>